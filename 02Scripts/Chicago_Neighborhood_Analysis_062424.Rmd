---
title: "Chicago Modeling: Probit - R data"
author: "Renata"
date: "2022-12-08"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)


#library(stevemisc) #for simulating censured continuous data
#source( '../orFunctions_jsc.R' )
#Rcpp::sourceCpp( '../cppFns.cpp' )

#visualize JAGS output
# library(MCMCvis)
# library(RcppArmadillo)
# library(stringr)

##Group means for segment data
library(dplyr)

##Visuals
library(ggplot2)

##dataframe manipulation
library(dplyr)

#for your diversity metrics
library(vegan)

#for beta regressions
library(betareg)
library(StepBeta)

#for stepwise poisson
library(My.stepwise)

```

```{r read in tree lvl data}
#read in full version of the tree dataset
TreeLvlCombined <- read.csv("../01Data/Chicago/091223AllYearsComb.csv")

TodayDate <- Sys.Date()
date <- format(TodayDate, format="%b%d%y")

##census data
CensusTracts2010 <- read.csv("../01Data/Chicago/Chicago2010Census_bySeg_fix.csv")
CensusTracts2020 <- read.csv("../01Data/Chicago/Chicago2020Census_bySeg_fix.csv")
HispLat2011 <- read.csv("../01Data/Chicago/Chicago_HispLat_ACS2011.csv")
HispLat2021 <- read.csv("../01Data/Chicago/Chicago_HispLat_ACS2021.csv")
MedHouseInc2011 <- read.csv("../01Data/Chicago/Chicago_MedHouseInc_ACS2011_2011InflAdj.csv")
MedHouseInc2021 <- read.csv("../01Data/Chicago/Chicago_MedHouseInc_ACS2021_2021InflAdj.csv")
HousingTenure2011 <- read.csv("../01Data/Chicago/Chicago_HousingTenure_ACS2011.csv")
HousingTenure2021 <- read.csv("../01Data/Chicago/Chicago_HousingTenure_ACS2021.csv")
SVIData <- read.csv("../01Data/Chicago/CookCounty_SVI.csv")

##zoning data
ZoningData <- read.csv("../01Data/Chicago/ChicagoZoning_bySeg_fix.csv")
ZoningDescr <- read.csv("../01Data/Chicago/ChicagoZoningDescriptions.csv")

#building data
BFoot  <- read.csv("../01Data/Chicago/ChicagoBuildings_bySeg_fix.csv")
BPerm  <- read.csv("../01Data/Chicago/ChicagoPermits_bySeg.csv")

##temperature - from arcPro layer (city 2023 data collection)
segnms <- c("49", "157", "55", "153", "244", 
            "275", "57", "128", "292", "281",
            "306", "324", "16")
segAftT <- c(92.687859, 93.179924, 92.795319, 91.908501, 91.773087,
             92.472115, 92.776642, 92.824524, 92.549370, 92.063988,
             91.616646, 93.441490, 92.428925)

SegmentTemp <- as.data.frame(matrix(c(segnms, segAftT), ncol=2, byrow = FALSE))
names(SegmentTemp) <- c("Segment", "AfternoonTemp")

#convert to celsius
SegmentTemp$AfternoonTemp <- (as.numeric(SegmentTemp$AfternoonTemp) - 32)*5/9
```


##Useful Functions
```{r useful funcs}
sumSquares <- function(predicted, actual){
  
  ss <- 0
  
  for(s in 1:length(predicted)){
    
    ss <- ss + (predicted[s] - actual[s])^2
    
    if( is.na(ss)){
      
      print(paste("ERROR: at iteration", s, "ss became NA"))
      
      break
      
    }
    
  }
  
  return(ss)
}

basalArea <- function(dbh){
  
 dbh_cm <- dbh*2.54
  ba <- (pi * (dbh_cm/2)^2)/10000
  return(ba)
}

#weighted avg function
weAvg <- function(column1, weights){
  wa <- sum(column1 * weights)
  return(wa)
  
}
```


## Get census data
Should do some kind of weighted average here, not just a basic average.

Should add SVI data (this is 2022 census tract)

```{r avg census data}

####Create combined census data
## inflation adjustment: 1.2037 - https://data.bls.gov/cgi-bin/cpicalc.pl?cost1=100.00&year1=201106&year2=202106 
MedHouseInc2011$MedIncome2021Dolars <- as.numeric(MedHouseInc2011$Estimate..Median.household.income.in.the.past.12.months..in.2011.inflation.adjusted.dollars.) * 1.2037

##pull in all information to a combined CensusData file
CensusTracts2010$PercHispLat <- HispLat2011$Estimate..Total..Hispanic.or.Latino[match(CensusTracts2010$geoid10, HispLat2011$geoid10)]/HispLat2011$Estimate..Total[match(CensusTracts2010$geoid10, HispLat2011$geoid10)]
CensusTracts2010$PercWhiteNonHisp <- HispLat2011$Estimate..Total..Not.Hispanic.or.Latino..White.alone[match(CensusTracts2010$geoid10, HispLat2011$geoid10)]/HispLat2011$Estimate..Total[match(CensusTracts2010$geoid10, HispLat2011$geoid10)]
CensusTracts2010$PercBlack <- (HispLat2011$Estimate..Total..Not.Hispanic.or.Latino..Black.or.African.American.alone[match(CensusTracts2010$geoid10, HispLat2011$geoid10)] + HispLat2011$Estimate..Total..Hispanic.or.Latino..Black.or.African.American.alone[match(CensusTracts2010$geoid10, HispLat2011$geoid10)])/HispLat2011$Estimate..Total[match(CensusTracts2010$geoid10, HispLat2011$geoid10)]
CensusTracts2010$MedHouseIncome <- MedHouseInc2011$MedIncome2021Dolars[match(CensusTracts2010$geoid10, MedHouseInc2011$geoid10)]
CensusTracts2010$PercRenter <- HousingTenure2011$Estimate..Total..Renter.occupied[match(CensusTracts2010$geoid10,HousingTenure2011$geoid10)]/HousingTenure2011$Estimate..Total[match(CensusTracts2010$geoid10,HousingTenure2011$geoid10)]
CensusTracts2010$PercMovL5Years <- c(HousingTenure2011$Estimate..Total..Owner.occupied..Moved.in.2005.or.later[match(CensusTracts2010$geoid10,HousingTenure2011$geoid10)] + HousingTenure2011$Estimate..Total..Renter.occupied..Moved.in.2005.or.later[match(CensusTracts2010$geoid10,HousingTenure2011$geoid10)])/HousingTenure2011$Estimate..Total[match(CensusTracts2010$geoid10,HousingTenure2011$geoid10)]

##missing income for 17031280900
CensusTracts2020$PercHispLat <- HispLat2021$Estimate..Total...Hispanic.or.Latino.[match(CensusTracts2020$GEOID, HispLat2021$geoid10)]/HispLat2021$Estimate..Total.[match(CensusTracts2020$GEOID, HispLat2021$geoid10)]
CensusTracts2020$PercWhiteNonHisp <- HispLat2021$Estimate..Total...Not.Hispanic.or.Latino...White.alone[match(CensusTracts2020$GEOID, HispLat2021$geoid10)]/HispLat2021$Estimate..Total.[match(CensusTracts2020$GEOID, HispLat2021$geoid10)]
CensusTracts2020$PercBlack <- (HispLat2021$Estimate..Total...Not.Hispanic.or.Latino...Black.or.African.American.alone[match(CensusTracts2020$GEOID, HispLat2021$geoid10)] + HispLat2021$Estimate..Total...Hispanic.or.Latino...Black.or.African.American.alone[match(CensusTracts2020$GEOID, HispLat2021$geoid10)])/HispLat2021$Estimate..Total.[match(CensusTracts2020$GEOID, HispLat2021$geoid10)]
CensusTracts2020$MedHouseIncome <- MedHouseInc2021$Estimate..Median.household.income.in.the.past.12.months..in.2021.inflation.adjusted.dollars.[match(CensusTracts2020$GEOID, MedHouseInc2021$geoid10)]
CensusTracts2020$PercRenter <- HousingTenure2021$Estimate..Total...Renter.occupied.[match(CensusTracts2020$GEOID, HousingTenure2021$geoid10)]/HousingTenure2021$Estimate..Total.[match(CensusTracts2020$GEOID, HousingTenure2021$geoid10)]
CensusTracts2020$PercMovL5Years <- c(HousingTenure2021$Estimate..Total...Owner.occupied...Moved.in.2019.or.later[match(CensusTracts2020$GEOID, HousingTenure2021$geoid10)] + HousingTenure2021$Estimate..Total...Renter.occupied...Moved.in.2019.or.later[match(CensusTracts2020$GEOID, HousingTenure2021$geoid10)])/HousingTenure2021$Estimate..Total.[match(CensusTracts2020$GEOID, HousingTenure2021$geoid10)]

##########################################deal with the census data
CensusData$SVI <- SVIData$OverallSVI[match(CensusData$GEOID, SVIData$FIPS)]

##set up weighted average
TotArea <- CensusData %>%
  group_by(Name) %>% summarize_at(vars("ShapeArea_m"), sum, na.rm=TRUE)

#so now we have the percent of the area for each segment
CensusData$PercentArea <- CensusData$ShapeArea_m/TotArea$ShapeArea_m[match(CensusData$Name, TotArea$Name)] 

finalCensusCols <- c("Segment", "TotalPop", "PercHispanicLatine", "PercBlack", "PercWhite", "MedHouseInc", "PercRent", "PercM19", "PercM15to18", "SVI")
SegmentCensusData <- as.data.frame(matrix(NA, nrow=length(TotArea$Name), ncol=length(finalCensusCols)))
names(SegmentCensusData) <- finalCensusCols

#to be able to average
CensusData[, c("Total_Population_1", "PercentHispanicLatine_1", "PercentBlack_1", "PercentWhite_1", "Median_Household_Income_1", "PercentRenter_1", "PercM19_1", "PercM15to18_1", "SVI")] <- sapply(CensusData[, c("Total_Population_1", "PercentHispanicLatine_1", "PercentBlack_1", "PercentWhite_1", "Median_Household_Income_1", "PercentRenter_1", "PercM19_1", "PercM15to18_1", "SVI")], as.numeric)


#get the weighted average
for (s in 1:length(TotArea$Name)){
  
  #get your segment data
  sdata <- CensusData[CensusData$Name == TotArea$Name[s], ]
  SegmentCensusData$Segment[s] <- TotArea$Name[s]
  
  ##simplify code ot get weighted average for the relevant columns
  SegmentCensusData[s, c("TotalPop", "PercHispanicLatine", "PercBlack", "PercWhite", 
                         "MedHouseInc", "PercRent", "PercM19", "PercM15to18", "SVI")] <- sapply(sdata[,c("Total_Population_1", "PercentHispanicLatine_1", "PercentBlack_1", "PercentWhite_1", "Median_Household_Income_1", "PercentRenter_1", "PercM19_1", "PercM15to18_1", "SVI")], weAvg, weights=sdata$PercentArea)

}

#change one segment name
SegmentCensusData$Segment[SegmentCensusData$Segment == "260/275"] <- "275"

```


##Get Building and Zoning Averages

```{r building and zoning averages}

##########################################Building data
#permitting information
BPerm$Year_issued <- format(as.Date(BPerm$PermitIssueDate, "%m/%d/%Y"), "%Y")

#get some easy tables to reference
perm_typs <- table(BPerm[,c("Segment", "PermitType")])
perm_yrs_const <- table(BPerm[BPerm$PermitType == "NewConst", c("Segment", "Year_issued")])
perm_yrs_reno <- table(BPerm[BPerm$PermitType == "Reno_Alt_add", c("Segment", "Year_issued")])

##create data frame to combine them all
BuiComb_nms <- c("Segment", "NumBuild", "NumConst_since06", "NumReno_since06", "NumConst_since15", "NumReno_since15", "NumDemo")
Seg_building <- as.data.frame(matrix(0, nrow=13, ncol=length(BuiComb_nms)))
names(Seg_building) <- BuiComb_nms

##building counts
BuiCount <- table(BFoot[,c("Name")])

#start filling out the combined dataframe
Seg_building$Segment <- names(BuiCount)
Seg_building$NumBuild <- BuiCount[match(Seg_building$Segment, names(BuiCount))]
Seg_building$NumConst_since06[match(rownames(perm_yrs_const), Seg_building$Segment)] <- rowSums(perm_yrs_const)
Seg_building$NumReno_since06[match(rownames(perm_yrs_reno), Seg_building$Segment)] <- rowSums(perm_yrs_reno)
Seg_building$NumConst_since15[match(rownames(perm_yrs_const), Seg_building$Segment)]  <- rowSums(perm_yrs_const[,c("2015", "2016", "2017", "2018", "2019", "2020")])
Seg_building$NumReno_since15[match(rownames(perm_yrs_reno), Seg_building$Segment)]  <- rowSums(perm_yrs_reno[,c( "2015", "2016", "2017", "2018", "2019", "2020")])
Seg_building$NumDemo[Seg_building$Segment == 244] <- 1

###########################Zoning Data
#######Get the data for a weighted average
TotArea <- ZoningData %>% 
  group_by(Name) %>%
  summarize_at(vars("Area_m2"), sum, na.rm=TRUE)

#get simplified zones to use
ZoningData$SimplifiedCat <- ZoningDescr$SimplifiedCategory[match(ZoningData$zone_class, ZoningDescr$zone_class)]

#dataframe to combine them all
zoning_cols <- c("Segment", "PercRes_z", "PercComm_z", "PercInd_z", "PercInst_z")
Zoning_bySeg <- as.data.frame(matrix(0, nrow=13, ncol=length(zoning_cols)))
names(Zoning_bySeg) <- zoning_cols

#get area for each zone in each segment
AreaBySimpleZone <- ZoningData %>% 
  group_by(Name, SimplifiedCat) %>%
  summarize_at(vars("Area_m2"), sum, na.rm=TRUE)

AreaBySimpleZone <- AreaBySimpleZone[!is.na(AreaBySimpleZone$SimplifiedCat),]
Zns <- c("Residential", "Commercial", "Industrial", "Institutional")
segs <- na.omit(unique(AreaBySimpleZone$Name))

#go through and get your averages
for (s in 1:length(segs)){
  
  sg <- segs[s]
  sdata <- na.omit(AreaBySimpleZone[AreaBySimpleZone$Name == sg,])
  Zoning_bySeg$Segment[s] <- sg
  Zoning_bySeg[s,(match(unique(sdata$SimplifiedCat), Zns) + 1)] <- sdata$Area_m2/TotArea$Area_m2[TotArea$Name == sg]
}

#to make it simpler later to combine data
Zoning_bySeg$Segment[Zoning_bySeg$Segment == "260/275"] <- "275"

```



##Get species data to pull in

```{r get species information}
#tree species information
SppSpecificData <- read.csv(paste(basicDataPath,"ProcessedData/SpeciesInformation_Chicago_Dirr.csv", sep=""))

#a little more intuitive
names(TreeLvlCombined)[names(TreeLvlCombined) == "CrownVigor"] <- "CrownStress"

#for ease later
TreeLvlCombined$GenSpe <- paste(TreeLvlCombined$Genus, TreeLvlCombined$Species, sep="_")

#To line up with species info
TreeLvlCombined$Species[TreeLvlCombined$Species == "unknown"] <- "spp."
TreeLvlCombined[, c("DroughtTol", "SaltTol", "UrbanApp")] <- rep(NA, length(TreeLvlCombined$TreeName))

##for a few weird species
londonplane <- c("x acerifolia", "hybrida")
TreeLvlCombined$Species[TreeLvlCombined$Species %in% londonplane] <- "x hispanica"
TreeLvlCombined$Species[TreeLvlCombined$Species == "sylvatica"] <- "silvatica" #for Nyssa silvatica

#row by row
for (t in 1:length(TreeLvlCombined$X)){
  YesGen <- SppSpecificData$SUB_GENUS == TreeLvlCombined$Genus[t]
  YesSpp <- SppSpecificData$SUB_SPECIES == TreeLvlCombined$Species[t]
  
  SppInfoInd <- c(1:length(SppSpecificData[,1]))[(YesGen & YesSpp)]
  
  #what do you do if you don't have info on this species
  if(length(SppInfoInd) == 0){
    print(paste("Error, no species information for", TreeLvlCombined$GenSpe[t], "Tree #", t))
    
    ##try to fill it in with the default for the genus
    Spp2 <- SppSpecificData$SUB_SPECIES =="spp."
    SppInfoInd2 <- c(1:length(SppSpecificData[,1]))[(YesGen & Spp2)]
    
    if(length(SppInfoInd2) == 0){
      print(paste("Error, no generic genus-level information for", TreeLvlCombined$Genus[t], "Tree #", t))
      next #go to the next tree
    } else {
      TreeLvlCombined$DroughtTol[t] <- SppSpecificData$DroughtTol[SppInfoInd2]
      TreeLvlCombined$SaltTol[t] <- SppSpecificData$SaltTol[SppInfoInd2]
      TreeLvlCombined$UrbanApp[t] <- SppSpecificData$StreetUrban[SppInfoInd2]
    }
  
  #have a species-level match
  } else {
    TreeLvlCombined$DroughtTol[t] <- SppSpecificData$DroughtTol[SppInfoInd]
    TreeLvlCombined$SaltTol[t] <- SppSpecificData$SaltTol[SppInfoInd]
    TreeLvlCombined$UrbanApp[t] <- SppSpecificData$StreetUrban[SppInfoInd]
  } #seeing if there is a match
  
}

##Species group adjustment
TreeLvlCombined$GenSpe[TreeLvlCombined$GenSpe == "Fraxinus_pennsylvanica" | TreeLvlCombined$GenSpe == "Fraxinus_unknown"] <- "Fraxinus spp."
TreeLvlCombined$GenSpe[(TreeLvlCombined$GenSpe == "Tilia_cordata") | (TreeLvlCombined$GenSpe == "Tilia_americana")] <- "Tilia spp." #small sample size and some cultivars
TreeLvlCombined$GenSpe[TreeLvlCombined$GenSpe == "Ulmus_americana"] <- "Ulmus spp." #unsure IDs
TreeLvlCombined$GenSpe[TreeLvlCombined$GenSpe == "Ulmus_pumila"| TreeLvlCombined$GenSpe == "Ulmus_unknown"] <- "Ulmus spp." #unsure IDs
SppFreq <- sort(table(TreeLvlCombined$GenSpe),decreasing = TRUE)
CommonSpp <- SppFreq[SppFreq > 50]

#Create a species group category
TreeLvlCombined$SppGroup <- rep("Other", length(TreeLvlCombined$TreeName))
TreeLvlCombined$SppGroup[TreeLvlCombined$GenSpe %in% names(CommonSpp)] <- TreeLvlCombined$GenSpe[TreeLvlCombined$GenSpe %in% names(CommonSpp)]
TreeLvlCombined$SppGroup <- as.factor(TreeLvlCombined$SppGroup) #for model
TreeLvlCombined$SppGroup <- relevel(TreeLvlCombined$SppGroup, ref = "Other")

##make a genus-lvl grouping 
TreeLvlCombined$GenusGroup <- TreeLvlCombined$Genus
GenusFreq <- table(TreeLvlCombined$Genus)
GenusFreq <- GenusFreq[GenusFreq > 40]
TreeLvlCombined$GenusGroup[!(TreeLvlCombined$GenusGroup %in% names(GenusFreq))] <- "01_Other"
TreeLvlCombined$GenusGroup <- as.factor(TreeLvlCombined$GenusGroup )
TreeLvlCombined$GenusGroup <- relevel(TreeLvlCombined$GenusGroup, ref = "01_Other")

```

##start to clean up tree-level data

Going through and making sure the format of the data matches that of Kamakura et al., in prep

```{r prep response data}
#Get rid of trees without local site conditions
TreeLvlCombined <- TreeLvlCombined[!is.na(TreeLvlCombined$Gardenscape),]

#convert dbh to basal area
TreeLvlCombined$BasalArea <- sapply(TreeLvlCombined$TotalDBH, basalArea) 

#Year
TreeLvlCombined$Year <- as.factor(TreeLvlCombined$Year)

#########################################Tree stress variables
#collapsing the categories here for ease
TreeLvlCombined$Dieback[((TreeLvlCombined$Dieback > 3) & (TreeLvlCombined$Dieback <= 6))] <- 4 #11-25%
TreeLvlCombined$Dieback[(TreeLvlCombined$Dieback > 6)] <- 5 #25%+
TreeLvlCombined$Dieback[TreeLvlCombined$CrownStress >= 5] <- 5 #trees are dead
TreeLvlCombined$Defoliation[TreeLvlCombined$Defoliation > 3] <- 3 #not enough variation (26%+)
TreeLvlCombined$Discoloration[TreeLvlCombined$Discoloration > 4] <- 4 #not enough variation (50%+)

#Get rid of 0.5 (that comes from the averages)
TreeLvlCombined$Discoloration <- round(TreeLvlCombined$Discoloration)
TreeLvlCombined$Defoliation <- round(TreeLvlCombined$Defoliation)
TreeLvlCombined$Dieback <- round(TreeLvlCombined$Dieback)

##CrownStress
TreeLvlCombined$CrownStress <- round(TreeLvlCombined$CrownStress, digits=0)

################################################Cues to care
##create Mulch categories
TreeLvlCombined$Mulch[TreeLvlCombined$Mulch == 1] <- "Mulch"
TreeLvlCombined$Mulch[TreeLvlCombined$Mulch == 0] <- "None"
TreeLvlCombined$Mulch[TreeLvlCombined$MulchVolcano == 1] <- "Volcano"

TreeLvlCombined$Mulch <- as.factor(TreeLvlCombined$Mulch)
TreeLvlCombined$Mulch <- relevel(TreeLvlCombined$Mulch, ref = "None")

##Simplify to a binary variable
TreeLvlCombined$CorrMulch <- TreeLvlCombined$Mulch
TreeLvlCombined$CorrMulch <- as.character(TreeLvlCombined$CorrMulch)
TreeLvlCombined$CorrMulch[TreeLvlCombined$CorrMulch == "Mulch"] <- 1
TreeLvlCombined$CorrMulch[TreeLvlCombined$CorrMulch != 1] <- 0

#Translate Gardenscape
TreeLvlCombined$Gardenscape[TreeLvlCombined$Gardenscape==""] <- "None"
h1 <- c("None", "Minimal", "Moderate", "Extensive")
h2 <- c(2:4,4)
GDict <- as.data.frame(matrix(c(h1,h2), nrow=4, ncol=2, byrow=FALSE))
names(GDict) <- c("Original", "Simplified")

TreeLvlCombined$Gardenscape <- GDict$Simplified[match(TreeLvlCombined$Gardenscape, GDict$Original)]
TreeLvlCombined$Gardenscape[TreeLvlCombined$Gardenscape == 2 & TreeLvlCombined$Mowing %in% c("old", "potentially never")] <- 1
TreeLvlCombined$Gardenscape <- as.factor(TreeLvlCombined$Gardenscape)

#Pruning
TreeLvlCombined$PrunedCorrect <-TreeLvlCombined$Pruned
TreeLvlCombined$PrunedCorrect[TreeLvlCombined$HatrackPrune == 1 | TreeLvlCombined$FlushCutPrune == 1] <- 0


###################################################Site condition variables

##Group Land Use categories
TreeLvlCombined$LandUse <- as.character(TreeLvlCombined$LandUse)
TreeLvlCombined$LandUse[TreeLvlCombined$LandUse == "SFR-A" | TreeLvlCombined$LandUse == "SFR-D"] <- "SFR"
TreeLvlCombined$LandUse[TreeLvlCombined$LandUse == "COMM" | TreeLvlCombined$LandUse == "MIX"] <- "COMM_Mx"
TreeLvlCombined$LandUse[TreeLvlCombined$LandUse == "V" | TreeLvlCombined$LandUse == "UT" | TreeLvlCombined$LandUse == "IND" | TreeLvlCombined$LandUse == "UT" | TreeLvlCombined$LandUse == "TR" | TreeLvlCombined$LandUse == "AG" | TreeLvlCombined$LandUse == "INST"| TreeLvlCombined$LandUse == "MP"] <- "Other"
TreeLvlCombined$LandUse <- as.factor(TreeLvlCombined$LandUse)
TreeLvlCombined$LandUse <- relevel(TreeLvlCombined$LandUse, ref = "Other")

##Need to modify the Percent Imperv because some of the categories are very infrequent
TreeLvlCombined$PercentImperv[TreeLvlCombined$PercentImperv <=2] <- 1 #less than 26% imperv
TreeLvlCombined$PercentImperv[TreeLvlCombined$PercentImperv ==3] <- 2 #26-50
TreeLvlCombined$PercentImperv[TreeLvlCombined$PercentImperv ==4] <- 3 #51-75
TreeLvlCombined$PercentImperv[TreeLvlCombined$PercentImperv ==5] <- 4 #76-100
TreeLvlCombined$PercentImperv <- as.factor(TreeLvlCombined$PercentImperv)

#Site type - simplify due to lack of variation
TreeLvlCombined$SiteType <- as.character(TreeLvlCombined$SiteType)
TreeLvlCombined$SiteType[is.null(TreeLvlCombined$SiteType) |TreeLvlCombined$SiteType== ""| TreeLvlCombined$SiteType== "MP" | TreeLvlCombined$SiteType == "OM" | TreeLvlCombined$SiteType == "OH"] <- "Other"
TreeLvlCombined$SiteType <- as.factor(TreeLvlCombined$SiteType)
TreeLvlCombined$SiteType <- relevel(TreeLvlCombined$SiteType, ref="SC")


```


## Convert to segment-level tree data

```{r pull in tree data}

##create a dataframe to storedata
colsSto <- names(TreeLvlCombined)
uniTrees <- unique(TreeLvlCombined$TreeName)
UniqueTreeData <- as.data.frame(matrix(0, ncol=length(colsSto), nrow = length(uniTrees)))
names(UniqueTreeData) <- colsSto

#get a version of the data to work with (easier to fix errors)
TreeData_SegLvl <- TreeLvlCombined

#change the formatting to be able to modify
TreeData_SegLvl$Year <- as.numeric(as.character(TreeData_SegLvl$Year))
TreeData_SegLvl$LandUse <- as.character(TreeData_SegLvl$LandUse)
TreeData_SegLvl$SiteType <- as.character(TreeData_SegLvl$SiteType)

#iterator
MatInd <- 1

#get one row per tree
for (u in 1:length(uniTrees)){
  
  treeName <- uniTrees[u]
  treedata <- TreeData_SegLvl[TreeData_SegLvl$TreeName == treeName,]
  
  mostRecYr <- max(treedata$Year)
  
  Dat2Use <- treedata[treedata$Year == mostRecYr, ]
  
  UniqueTreeData[MatInd,] <- Dat2Use[1,]
  
  MatInd <- MatInd + 1
  
}

##set up data for diversity indices - first at the species level
UniqueTreeData <- UniqueTreeData[UniqueTreeData$Segment != "UIC",] #get rid of the baseline data
UniqueTreeData$CorrMulch <- as.numeric(UniqueTreeData$CorrMulch)


SppSeg <- table(UniqueTreeData[, c("Segment", "GenSpe")]) #check about these species IDs
#shannonDivSegs <- diversity(SppSeg, index="shannon")
simpsonDivSegs <- diversity(SppSeg, index="simpson")

#now at the level of genera
GenSeg <- table(UniqueTreeData[, c("Segment", "Genus")])
#shannonDivSegs_gen <- diversity(GenSeg, index="shannon")
simpsonDivSegs_gen <- diversity(GenSeg, index="simpson")

#############################################################RESTART CLEANING HERE

SegAvg_UniqueDat <- UniqueTreeData %>%
  group_by(Segment) %>%
  summarize_at(vars("BasalArea", "CrownLight", "CorrMulch", "PrunedCorrect", "UrbanApp", "TrunkDamage", "TreeGuard"), mean, na.rm=TRUE)

TotalSegTrees <- table(UniqueTreeData$Segment)

#Site Type
Seg_SiteType_Counts <- table(UniqueTreeData[,c("Segment", "SiteType")])
Perc_SegST <- sweep(Seg_SiteType_Counts, 1, TotalSegTrees, FUN='/')
#from this, probably most useful to look at percent SC or SP and then Percent FY or SY
#with mod, use SP, SC, Yard

#Land Use
Seg_LandUse_Counts <- table(UniqueTreeData[,c("Segment", "LandUse")])
Perc_SegLU <- sweep(Seg_LandUse_Counts, 1, TotalSegTrees, FUN='/')
#here, look at Res vs COMM

#Percent Impervious
Seg_PI_Counts <- table(UniqueTreeData[,c("Segment", "PercentImperv")])
Perc_SegPI <- sweep(Seg_PI_Counts, 1, TotalSegTrees, FUN='/')
#kind of like your analyses, maybe combine 1 and 2, then 3, then 4 and 5 combined

#Gardenscape
Seg_Gardenscape_Counts <- table(UniqueTreeData[,c("Segment", "Gardenscape")])
Perc_SegGard <- sweep(Seg_Gardenscape_Counts, 1, TotalSegTrees, FUN='/')
#use whatever you used in the analyses above
#do 1, 2, 3+?, or maybe do 1 and 4/5 and leave the rest to be moderate?

#Tree Health
#should use the same groupings as I did for the analyses above
#for these it is probably worth pulling in all the cateories to start with and adjust as needed
#maybe ignore defoliation because you only have 2 categories?
Seg_Discol_Counts <- table(UniqueTreeData[,c("Segment", "Discoloration")])
Perc_SegDisc <- sweep(Seg_Discol_Counts, 1, TotalSegTrees, FUN='/')
Seg_Defol_Counts <- table(UniqueTreeData[,c("Segment", "Defoliation")])
Perc_SegDef <- sweep(Seg_Defol_Counts, 1, TotalSegTrees, FUN='/')
Seg_DBK_Counts <- table(UniqueTreeData[,c("Segment", "Dieback")])
Perc_SegDBK <- sweep(Seg_DBK_Counts, 1, TotalSegTrees, FUN='/')
Seg_CS_Counts <- table(UniqueTreeData[,c("Segment", "CrownStress")])
Perc_SegCS <- sweep(Seg_CS_Counts, 1, TotalSegTrees, FUN='/')
Seg_UrbanApp_Counts <- table(UniqueTreeData[,c("Segment", "UrbanApp")])
Perc_SegUA <- sweep(Seg_UrbanApp_Counts, 1, TotalSegTrees, FUN='/')

##################################################Combine all the data
nrows <- length(SegmentCensusData$Segment)
SegDatCols <- c("Segment", "PercentRenter", "MedianHouseholdIncome", "PercWhite", "PercentBlack", "PercHL", "MovL5Yrs", "SVI", "AvgBA", "PercCorrMulch", "PercUrbanApp", "PercResTree", "PercCOMM_MxTree", "PercSC", "PercGar3o4", "PercDisc3o4", "PercDBK5", "PercCS4o5", "SimpsonsDivSpp", "SimpsonsDivGen", "totNumTrees")
SegmentLvlDat <- as.data.frame(matrix(NA, nrow=nrows, ncol=length(SegDatCols)))
names(SegmentLvlDat) <- SegDatCols

SegNms <- unique(SegmentCensusData$Segment)


##Add census data to empty df
for(s in 1:length(SegNms)){
  
  seg <- SegNms[s]
  SegmentLvlDat$Segment[s] <- seg
  
  seg_ind <- match(seg, SegmentCensusData$Segment)
  
  #Census Data
  SegmentLvlDat$PercentRenter[s] <- SegmentCensusData$PercRent[seg_ind]
  SegmentLvlDat$MedianHouseholdIncome[s] <- SegmentCensusData$MedHouseInc[seg_ind]
  SegmentLvlDat$PercWhite[s] <- SegmentCensusData$PercWhite[seg_ind]
  SegmentLvlDat$PercentBlack[s] <- SegmentCensusData$PercBlack[seg_ind]
  SegmentLvlDat$PercHL[s] <- SegmentCensusData$PercHispanicLatine[seg_ind]
  SegmentLvlDat$MovL5Yrs[s] <- SegmentCensusData$PercM19[seg_ind] + SegmentCensusData$PercM15to18[seg_ind]
  SegmentLvlDat$SVI[s] <- SegmentCensusData$SVI[seg_ind]
  
  ####Pull in the non-census data
  SegInd_treed <- match(seg, SegAvg_UniqueDat$Segment)
  
  SegmentLvlDat$AvgBA[s] <- SegAvg_UniqueDat$BasalArea[SegInd_treed]
  SegmentLvlDat$PercUrbanApp[s] <- SegAvg_UniqueDat$UrbanApp[SegInd_treed]
  SegmentLvlDat$PercCorrMulch[s] <- SegAvg_UniqueDat$CorrMulch[SegInd_treed]
  SegmentLvlDat$PercGar3o4[s] <- Perc_SegGard[SegInd_treed,match("3", colnames(Perc_SegGard))] + Perc_SegGard[SegInd_treed,match("4", colnames(Perc_SegGard))]
  
  ##have to pull from other summaries
  SegmentLvlDat$PercResTree[s] <- Perc_SegLU[SegInd_treed, ("MFR")] +  Perc_SegLU[SegInd_treed, ("SFR")]
  SegmentLvlDat$PercCOMM_MxTree[s] <- Perc_SegLU[SegInd_treed, ("COMM_Mx")]
  SegmentLvlDat$PercSC[s] <- Perc_SegST[SegInd_treed, match("SC", colnames(Perc_SegST))]
  
  
  #tree health outcomes
  SegmentLvlDat$PercDisc3o4[s] <- Perc_SegDisc[SegInd_treed, match("3", colnames(Perc_SegDisc))] + Perc_SegDisc[SegInd_treed, match("4", colnames(Perc_SegDisc))]
  SegmentLvlDat$PercDBK5[s] <- Perc_SegDBK[SegInd_treed, match("5", colnames(Perc_SegDBK))]
  SegmentLvlDat$PercCS4o5[s] <- Perc_SegCS[SegInd_treed, match("4", colnames(Perc_SegCS))] + Perc_SegCS[SegInd_treed, match("5", colnames(Perc_SegCS))]
  
  ##Diversity
  SegmentLvlDat$SimpsonsDivSpp[s] <- as.vector(simpsonDivSegs[match(seg, names(simpsonDivSegs))])
  SegmentLvlDat$SimpsonsDivGen[s]<- as.vector(simpsonDivSegs_gen[match(seg, names(simpsonDivSegs_gen))])
  
  #basic info
  SegmentLvlDat$totNumTrees[s] <- table(UniqueTreeData[,c("Segment")])[SegInd_treed]
  
}

SegmentLvlDat <- SegmentLvlDat[!is.na(SegmentLvlDat$Segment),]


```


##Combine all seg-lvl data

```{r combine all data}
#SegmentLvlDat
#Zoning_bySeg
#Seg_building

Seg_allData <- cbind(SegmentLvlDat, Zoning_bySeg, Seg_building)

Seg_allData$AftTemp <- SegmentTemp$AfternoonTemp[match(Seg_allData$Segment, SegmentTemp$Segment)]

AnalysisCols <- c("PercComm_z", "PercSC", "PercGar3o4", "PercCorrMulch", "AvgBA","PercUrbanApp",  "PercDisc3o4", "PercDBK5", "PercCS4o5")

#go through and slightly adjust the variables that will be modeled with a beta distribution
for(c in 1:length(AnalysisCols)){
  
  v <- AnalysisCols[c]
  v_ind <- match(v, names(Seg_allData))
  
  Seg_allData[(Seg_allData[,v_ind] == 0) ,v_ind] <- 0.0001
  Seg_allData[(Seg_allData[,v_ind] == 1) ,v_ind] <- 0.9999
  
}

```


##start looking at some basic regressions

Need to start out by looking at the correlations between variables
* even with my efforts to stratify, percent renter and median household income are relatively correlated
* median household income and percent white are super correlated
* Percent white and percent Black are relatively highly correlated
* population density is good with all of them though, highest is percent renter and that is 0.38
* Percent renter is relatively highly correlated to race too

Need to look more into the weights - https://copyprogramming.com/howto/fitting-a-betareg-model-with-weights-in-r 
* basically duplicates the values so if you have 90 trees, it is like you observed the value 90 times, whereas if you have 30 trees, you observed the value 50 times


Beta Bayesian: https://cran.r-project.org/web/packages/betaBayes/betaBayes.pdf
* problem is that it doesn't have weights


```{r basic regressions}

wts <- as.vector(Seg_allData$totNumTrees)

#to get a sense of the correlations
cor(Seg_allData[c("PercComm_z", "PercInd_z","NumConst_since15","NumReno_since15", "NumBuild", "MedianHouseholdIncome", 
                  "MovL5Yrs", "PercCOMM_MxTree", "PercWhite", "PercentBlack", "PercHL")])

##try combining percHL with percBlack
Seg_allData$PercBlack_HL <- Seg_allData$PercentBlack + Seg_allData$PercHL

#to get a sense of the correlations
cor(Seg_allData[c("PercComm_z", "PercInd_z","NumConst_since15","NumReno_since15", "NumBuild", "MedianHouseholdIncome", 
                  "MovL5Yrs", "PercCOMM_MxTree", "PercWhite", "PercentBlack", "PercHL", "PercBlack_HL", "SVI")])

###########Model options without super correlated variables

#m1  - PercComm, PercBlack_HL, NumBuild, MoveL5Yrs
#m2 - PercComm, Median Household Income, NumBuild, MoveL5Yrs
#m3 - PercComm, SVI, NumBuild, MoveL5Yrs
#m4 - PercComm, NumConst, NumBuild, MoveL5Yrs
#m5 - PercComm, NumReno, NumBuild, MoveL5Yrs

f1 <- "PercCOMM_MxTree + PercBlack_HL + NumBuild + MovL5Yrs"
f2 <- "PercCOMM_MxTree + MedianHouseholdIncome + NumBuild + MovL5Yrs"
f3 <- "PercCOMM_MxTree + SVI + NumBuild + MovL5Yrs"
f4 <- "PercCOMM_MxTree + NumConst_since15 + NumBuild + MovL5Yrs"
f5 <- "PercCOMM_MxTree + NumReno_since15 + NumBuild + MovL5Yrs"


#############################Sidewalk cutout
mods_m1 <- paste(rep("PercSC ~", 5), c(f1, f2, f3, f4, f5))

f1mod.1 <- betareg(mods_m1[1], data=Seg_allData, weights=wts)
bestf1mod.1 <- StepBeta(f1mod.1)
f1sum.1 <- summary(bestf1mod.1)

f1mod.2 <- betareg(mods_m1[2], data=Seg_allData, weights=wts)
bestf1mod.2 <- StepBeta(f1mod.2)
f1sum.2 <- summary(bestf1mod.2)

f1mod.3 <- betareg(mods_m1[3], data=Seg_allData, weights=wts)
bestf1mod.3 <- StepBeta(f1mod.3)
f1sum.3 <- summary(bestf1mod.3)

f1mod.4 <- betareg(mods_m1[4], data=Seg_allData, weights=wts)
bestf1mod.4 <- StepBeta(f1mod.4)
f1sum.4 <- summary(bestf1mod.4)

f1mod.5 <- betareg(mods_m1[5], data=Seg_allData, weights=wts)
bestf1mod.5 <- StepBeta(f1mod.5)
f1sum.5 <- summary(bestf1mod.5)


AIC(bestf1mod.1, bestf1mod.2, bestf1mod.3, bestf1mod.4, bestf1mod.5)

##            df       AIC
# bestf1mod.1  6 -2566.064
# bestf1mod.2  6 -2572.864
# bestf1mod.3  5 -2879.950
# bestf1mod.4  5 -2943.194 ** - pseudo r2: 0.3464
# bestf1mod.5  6 -2562.941 

write.csv(f1sum.4$coefficients$mean, "../05Outputs/ModelRuns062824/Chi_SC_Best_m4.csv")

###################################Afternoon Temperature - linreg
mods_m2 <- paste(rep("AftTemp ~", 5), c(f1, f2, f3, f4, f5))

f2mod.1 <- lm(mods_m2[1], data=Seg_allData, weights=wts)
bestf2mod.1 <- step(f2mod.1, direction="both")
f2sum.1 <- summary(bestf2mod.1)

f2mod.2 <- lm(mods_m2[2], data=Seg_allData, weights=wts)
bestf2mod.2 <- step(f2mod.2, direction="both")
f2sum.2 <- summary(bestf2mod.2)

f2mod.3 <- lm(mods_m2[3], data=Seg_allData, weights=wts)
bestf2mod.3 <- step(f2mod.3, direction="both")
f2sum.3 <- summary(bestf2mod.3)

f2mod.4 <- lm(mods_m2[4], data=Seg_allData, weights=wts)
bestf2mod.4 <- step(f2mod.4, direction="both")
f2sum.4 <- summary(bestf2mod.4)

f2mod.5 <- lm(mods_m2[5], data=Seg_allData, weights=wts)
bestf2mod.5 <- step(f2mod.5, direction="both")
f2sum.5 <- summary(bestf2mod.5)

AIC(bestf2mod.1, bestf2mod.2, bestf2mod.3, bestf2mod.4, bestf2mod.5)

#             df       AIC
# bestf2mod.1  2 10.687082
# bestf2mod.2  2 10.687082
# bestf2mod.3  2 10.687082
# bestf2mod.4  2 10.687082
# bestf2mod.5  3  9.501646** - adjusted r2: 0.1462

#write.csv(f2sum.5$coefficients, "../05Outputs/ModelRuns062824/Chi_Temperature_Best_m5.csv")

###########################Percent Gardenscape 3 or 4
mods_m3 <- paste(rep("PercGar3o4 ~", 5), c(f1, f2, f3, f4, f5))


f3mod.1 <- betareg(mods_m3[1], data=Seg_allData, weights=wts)
bestf3mod.1 <- StepBeta(f3mod.1)
f3sum.1 <- summary(bestf3mod.1)

f3mod.2 <- betareg(mods_m3[2], data=Seg_allData, weights=wts)
bestf3mod.2 <- StepBeta(f3mod.2)
f3sum.2 <- summary(bestf3mod.2)

f3mod.3 <- betareg(mods_m3[3], data=Seg_allData, weights=wts)
bestf3mod.3 <- StepBeta(f3mod.3)
f3sum.3 <- summary(bestf3mod.3)

f3mod.4 <- betareg(mods_m3[4], data=Seg_allData, weights=wts)
bestf3mod.4 <- StepBeta(f3mod.4)
f3sum.4 <- summary(bestf3mod.4)

f3mod.5 <- betareg(mods_m3[5], data=Seg_allData, weights=wts)
bestf3mod.5 <- StepBeta(f3mod.5)
f3sum.5 <- summary(bestf3mod.5)


AIC(bestf3mod.1, bestf3mod.2, bestf3mod.3, bestf3mod.4, bestf3mod.5)

#             df       AIC
# bestf3mod.1  6 -1802.416******* Psuedo r2 - 0.2111
# bestf3mod.2  6 -1775.398
# bestf3mod.3  6 -1772.376
# bestf3mod.4  5 -1713.637
# bestf3mod.5  6 -1796.449

#write.csv(f3sum.1$coefficients$mean, "../05Outputs/ModelRuns062824/Chi_Gardenscape_Best_m1.csv")


```


```{r best model for tree-related}
########################### Simpson Diversity - species
mods_m4 <- paste(rep("SimpsonsDivSpp ~", 5), c(f1, f2, f3, f4, f5))


f4mod.1 <- betareg(mods_m4[1], data=Seg_allData, weights=wts)
bestf4mod.1 <- StepBeta(f4mod.1)
f4sum.1 <- summary(bestf4mod.1)

f4mod.2 <- betareg(mods_m4[2], data=Seg_allData, weights=wts)
bestf4mod.2 <- StepBeta(f4mod.2)
f4sum.2 <- summary(bestf4mod.2)

f4mod.3 <- betareg(mods_m4[3], data=Seg_allData, weights=wts)
bestf4mod.3 <- StepBeta(f4mod.3)
f4sum.3 <- summary(bestf4mod.3)

f4mod.4 <- betareg(mods_m4[4], data=Seg_allData, weights=wts)
bestf4mod.4 <- StepBeta(f4mod.4)
f4sum.4 <- summary(bestf4mod.4)

f4mod.5 <- betareg(mods_m4[5], data=Seg_allData, weights=wts)
bestf4mod.5 <- StepBeta(f4mod.5)
f4sum.5 <- summary(bestf4mod.5)


AIC(bestf4mod.1, bestf4mod.2, bestf4mod.3, bestf4mod.4, bestf4mod.5)

#             df       AIC
# bestf4mod.1  6 -3130.756
# bestf4mod.2  6 -3230.506 ** - psuedo r2: 0.3373
# bestf4mod.3  6 -3227.265
# bestf4mod.4  5 -3133.703
# bestf4mod.5  5 -3205.501

#write.csv(f4sum.2$coefficients$mean, "../05Outputs/ModelRuns062824/Chi_SimpsonSpp_Best_m2.csv")

############################ Simpson Diversity - genus
mods_m5 <- paste(rep("SimpsonsDivGen ~", 5), c(f1, f2, f3, f4, f5))

f5mod.1 <- betareg(mods_m5[1], data=Seg_allData, weights=wts)
bestf5mod.1 <- StepBeta(f5mod.1)
f5sum.1 <- summary(bestf5mod.1)

f5mod.2 <- betareg(mods_m5[2], data=Seg_allData, weights=wts)
bestf5mod.2 <- StepBeta(f5mod.2)
f5sum.2 <- summary(bestf5mod.2)

f5mod.3 <- betareg(mods_m5[3], data=Seg_allData, weights=wts)
bestf5mod.3 <- StepBeta(f5mod.3)
f5sum.3 <- summary(bestf5mod.3)

f5mod.4 <- betareg(mods_m5[4], data=Seg_allData, weights=wts)
bestf5mod.4 <- StepBeta(f5mod.4)
f5sum.4 <- summary(bestf5mod.4)

f5mod.5 <- betareg(mods_m5[5], data=Seg_allData, weights=wts)
bestf5mod.5 <- StepBeta(f5mod.5)
f5sum.5 <- summary(bestf5mod.5)


AIC(bestf5mod.1, bestf5mod.2, bestf5mod.3, bestf5mod.4, bestf5mod.5)

#             df       AIC
# bestf5mod.1  6 -2469.883
# bestf5mod.2  6 -2507.387
# bestf5mod.3  6 -2556.699 ** pseudo r2: 0.2588
# bestf5mod.4  6 -2481.456
# bestf5mod.5  4 -2507.494

#write.csv(f5sum.3$coefficients$mean, "../05Outputs/ModelRuns062824/Chi_SimpsonGen_Best_m3.csv")


###AvgBA
mods_m6 <- paste(rep("AvgBA ~", 5), c(f1, f2, f3, f4, f5))

f6mod.1 <- lm(mods_m6[1], data=Seg_allData, weights=wts)
bestf6mod.1 <- step(f6mod.1, direction="both")
f6sum.1 <- summary(bestf6mod.1)

f6mod.2 <- lm(mods_m6[2], data=Seg_allData, weights=wts)
bestf6mod.2 <- step(f6mod.2, direction="both")
f6sum.2 <- summary(bestf6mod.2)

f6mod.3 <- lm(mods_m6[3], data=Seg_allData, weights=wts)
bestf6mod.3 <- step(f6mod.3, direction="both")
f6sum.3 <- summary(bestf6mod.3)

f6mod.4 <- lm(mods_m6[4], data=Seg_allData, weights=wts)
bestf6mod.4 <- step(f6mod.4, direction="both")
f6sum.4 <- summary(bestf6mod.4)

f6mod.5 <- lm(mods_m6[5], data=Seg_allData, weights=wts)
bestf6mod.5 <- step(f6mod.5, direction="both")
f6sum.5 <- summary(bestf6mod.5)


AIC(bestf6mod.1, bestf6mod.2, bestf6mod.3, bestf6mod.4, bestf6mod.5)

#             df       AIC
# bestf6mod.1  3 -40.62378
# bestf6mod.2  3 -40.62378
# bestf6mod.3  5 -41.35677
# bestf6mod.4  5 -42.67746 ** - adjusted r2: 0.5157
# bestf6mod.5  3 -40.62378

#write.csv(f6sum.4$coefficients, "../05Outputs/ModelRuns062824/Chi_AvgBA_Best_m3.csv")

##Number of Trees
mods_m7 <- paste(rep("totNumTrees ~", 5), c(f1, f2, f3, f4, f5))

f7mod.1 <- step(glm(mods_m7[1], family="poisson", data=Seg_allData))
f7sum.1 <- summary(f7mod.1)

f7mod.2 <- step(glm(mods_m7[2], family="poisson", data=Seg_allData))
f7sum.2 <- summary(f7mod.2)

f7mod.3 <- step(glm(mods_m7[3], family="poisson", data=Seg_allData))
f7sum.3 <- summary(f7mod.3)

f7mod.4 <- step(glm(mods_m7[4], family="poisson", data=Seg_allData))
f7sum.4 <- summary(f7mod.4)

f7mod.5 <- step(glm(mods_m7[5], family="poisson", data=Seg_allData))
f7sum.5 <- summary(f7mod.5)

AIC(f7mod.1, f7mod.2, f7mod.3, f7mod.4, f7mod.5)

#         df      AIC
# f7mod.1  4 107.4581** # pseudo r2: 0.7766527
# f7mod.2  4 108.0166
# f7mod.3  4 115.0608
# f7mod.4  4 116.2869
# f7mod.5  4 114.3975

#write.csv(f7sum.1$coefficients, "../05Outputs/ModelRuns062824/Chi_NumTrees_Best_m1.csv")

###Urban Tolerance
mods_m8 <- paste(rep("PercUrbanApp ~", 5), c(f1, f2, f3, f4, f5))

f8mod.1 <- betareg(mods_m8[1], data=Seg_allData, weights=wts)
bestf8mod.1 <- StepBeta(f8mod.1)
f8sum.1 <- summary(bestf8mod.1)

f8mod.2 <- betareg(mods_m8[2], data=Seg_allData, weights=wts)
bestf8mod.2 <- StepBeta(f8mod.2)
f8sum.2 <- summary(bestf8mod.2)

f8mod.3 <- betareg(mods_m8[3], data=Seg_allData, weights=wts)
bestf8mod.3 <- StepBeta(f8mod.3)
f8sum.3 <- summary(bestf8mod.3)

f8mod.4 <- betareg(mods_m8[4], data=Seg_allData, weights=wts)
bestf8mod.4 <- StepBeta(f8mod.4)
f8sum.4 <- summary(bestf8mod.4)

f8mod.5 <- betareg(mods_m8[5], data=Seg_allData, weights=wts)
bestf8mod.5 <- StepBeta(f8mod.5)
f8sum.5 <- summary(bestf8mod.5)


AIC(bestf8mod.1, bestf8mod.2, bestf8mod.3, bestf8mod.4, bestf8mod.5)

#             df       AIC
# bestf8mod.1  6 -1571.848
# bestf8mod.2  6 -1686.509**
# bestf8mod.3  6 -1496.801
# bestf8mod.4  6 -1385.222
# bestf8mod.5  6 -1548.654

#write.csv(f8sum.2$coefficients, "../05Outputs/ModelRuns062824/Chi_UrbanApp_Best_m2.csv")
##########################################################Tree Health

###########################PercDisc3o4
mods_m9 <- paste(rep("PercDisc3o4 ~", 5), c(f1, f2, f3, f4, f5))

f9mod.1 <- betareg(mods_m9[1], data=Seg_allData, weights=wts)
bestf9mod.1 <- StepBeta(f9mod.1)
f9sum.1 <- summary(bestf9mod.1)

f9mod.2 <- betareg(mods_m9[2], data=Seg_allData, weights=wts)
bestf9mod.2 <- StepBeta(f9mod.2)
f9sum.2 <- summary(bestf9mod.2)

f9mod.3 <- betareg(mods_m9[3], data=Seg_allData, weights=wts)
bestf9mod.3 <- StepBeta(f9mod.3)
f9sum.3 <- summary(bestf9mod.3)

f9mod.4 <- betareg(mods_m9[4], data=Seg_allData, weights=wts)
bestf9mod.4 <- StepBeta(f9mod.4)
f9sum.4 <- summary(bestf9mod.4)

f9mod.5 <- betareg(mods_m9[5], data=Seg_allData, weights=wts)
bestf9mod.5 <- StepBeta(f9mod.5)
f9sum.5 <- summary(bestf9mod.5)

AIC(bestf9mod.1, bestf9mod.2, bestf9mod.3, bestf9mod.4, bestf9mod.5)

#             df       AIC
# bestf9mod.1  6 -3128.210
# bestf9mod.2  5 -3125.116
# bestf9mod.3  6 -3149.472
# bestf9mod.4  6 -3141.852
# bestf9mod.5  6 -3180.813 **

#write.csv(f9sum.5$coefficients, "../05Outputs/ModelRuns062824/Chi_Discol_Best_m5.csv")

###########################PercDBK5
mods_m10 <- paste(rep("PercDBK5 ~", 5), c(f1, f2, f3, f4, f5))

f10mod.1 <- betareg(mods_m10[1], data=Seg_allData, weights=wts)
bestf10mod.1 <- StepBeta(f10mod.1)
f10sum.1 <- summary(bestf10mod.1)

f10mod.2 <- betareg(mods_m10[2], data=Seg_allData, weights=wts)
bestf10mod.2 <- StepBeta(f10mod.2)
f10sum.2 <- summary(bestf10mod.2)

f10mod.3 <- betareg(mods_m10[3], data=Seg_allData, weights=wts)
bestf10mod.3 <- StepBeta(f10mod.3)
f10sum.3 <- summary(bestf10mod.3)

f10mod.4 <- betareg(mods_m10[4], data=Seg_allData, weights=wts)
bestf10mod.4 <- StepBeta(f10mod.4)
f10sum.4 <- summary(bestf10mod.4)

f10mod.5 <- betareg(mods_m10[5], data=Seg_allData, weights=wts)
bestf10mod.5 <- StepBeta(f10mod.5)
f10sum.5 <- summary(bestf10mod.5)

AIC(bestf10mod.1, bestf10mod.2, bestf10mod.3, bestf10mod.4, bestf10mod.5)

#              df       AIC
# bestf10mod.1  6 -3353.627 **
# bestf10mod.2  6 -3206.726
# bestf10mod.3  6 -3143.132
# bestf10mod.4  6 -3219.582
# bestf10mod.5  6 -3244.438

#write.csv(f10sum.1$coefficients, "../05Outputs/ModelRuns062824/Chi_DBK_Best_m1.csv")

###########################PercCS4o5
mods_m11 <- paste(rep("PercCS4o5 ~", 5), c(f1, f2, f3, f4, f5))

f11mod.1 <- betareg(mods_m11[1], data=Seg_allData, weights=wts)
bestf11mod.1 <- StepBeta(f11mod.1)
f11sum.1 <- summary(bestf11mod.1)

f11mod.2 <- betareg(mods_m11[2], data=Seg_allData, weights=wts)
bestf11mod.2 <- StepBeta(f11mod.2)
f11sum.2 <- summary(bestf11mod.2)

f11mod.3 <- betareg(mods_m11[3], data=Seg_allData, weights=wts)
bestf11mod.3 <- StepBeta(f11mod.3)
f11sum.3 <- summary(bestf11mod.3)

f11mod.4 <- betareg(mods_m11[4], data=Seg_allData, weights=wts)
bestf11mod.4 <- StepBeta(f11mod.4)
f11sum.4 <- summary(bestf11mod.4)

f11mod.5 <- betareg(mods_m11[5], data=Seg_allData, weights=wts)
bestf11mod.5 <- StepBeta(f11mod.5)
f11sum.5 <- summary(bestf11mod.5)

AIC(bestf11mod.1, bestf11mod.2, bestf11mod.3, bestf11mod.4, bestf11mod.5)

#              df       AIC
# bestf11mod.1  6 -3037.557 **
# bestf11mod.2  6 -3011.811
# bestf11mod.3  6 -2930.851
# bestf11mod.4  6 -2942.338
# bestf11mod.5  6 -2880.210

#write.csv(f11sum.1$coefficients, "../05Outputs/ModelRuns062824/Chi_CS_Best_m1.csv")

##store data from the "best" models
cnms <- c("ModelType", "DepVar", "model", "R2")
ModOverview <- as.data.frame(matrix(0, nrow=11, ncol=length(cnms)))
names(ModOverview) <- cnms

modList <- list(f1sum.4, f2sum.5, f3sum.1, f4sum.2, f5sum.3, f6sum.4, f7sum.1, f8sum.2, f9sum.5, f10sum.1, f11sum.1)
modTyps <- c("beta","lin", "beta", "beta", "beta", "lin", "pois", "beta", "beta", "beta", "beta")
modDep <- c("PercSC", "AftTemp", "PercGar3o4", "SimpDivSpp", "SimpDivGen", "AvgBA", "NumTrees", "PercUrbanApp", "PercDisc", "PercDBK", "PercCS")

for (m in 1:11){

  mod <- modList[[m]]
  modT <- modTyps[m]

  ModOverview$ModelType[m] <- modT
  ModOverview$DepVar[m] <- modDep[m]

  #store data for diff model types
  if(modT == "beta"){

    ModOverview$model[m] <- as.character(mod$call)
    ModOverview$R2[m] <- mod$pseudo.r.squared

    pm <- mod$coefficients$mean

  } else if (modT == "lin"){

    ModOverview$model[m] <- as.character(mod$call)[2]
    ModOverview$R2[m] <- mod$adj.r.squared

    pm <- mod$coefficients

  }else if (modT == "pois"){
    ModOverview$model[m] <- as.character(mod$call)[2]
    ModOverview$R2[m] <- with(mod, 1-deviance/null.deviance)

    pm <- mod$coefficients

  }

  ##printout the coefficient values

  #write.csv(pm, paste("../01Data/Chicago/BetaVals", modDep[m], "since15_062824.csv", sep=""))


}

write.csv(ModOverview, "../05Outputs/ModelRuns062824/Chi_ModelOverviewResults_Since15_062824.csv")




```

